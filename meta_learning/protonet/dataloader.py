import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
import random


class DataLoader(object):
    def __init__(
        self,
        data_type: str = "train",
        n_way: int = 5,
        n_support: int = 5,
        n_query: int = 5,
    ):
        self.data_type = data_type
        self.data = self.preprocess_data(
            tfds.load(
                "omniglot",
                data_dir="./data",
                split=self.data_type,
                as_supervised=True,
            )
        )

        self.n_way = n_way
        self.n_support = n_support
        self.n_query = n_query
        self.task_list = None

    def preprocess_data(self, dataset):
        print(f"Preprocessing {self.data_type} Omniglot dataset")

        def preprocess(image, label):
            image = tf.image.convert_image_dtype(image, tf.float32)
            image = tf.image.rgb_to_grayscale(image)
            image = tf.image.resize(image, [28, 28])
            return image, label

        data = {}
        for image, label in dataset.map(preprocess):
            image = image.numpy()
            label = str(label.numpy())
            if label not in data:
                data[label] = []
            data[label].append(image)
        print("Finished preprocessing")
        return data

    def generate_task_list(
        self,
        n_tasks: int = 100,
        n_way: int = 0,
        n_query: int = 0,
        n_support: int = 0,
    ):
        n_way = self.n_way if n_way == 0 else n_way
        n_query = self.n_query if n_query == 0 else n_query
        n_support = self.n_support if n_support == 0 else n_support
        task_list = list()

        ############### Your code here ###################
        # TODO: finish implementing this method.
        # Append n_tasks number of tasks to task_list
        # where each task is a dictionary in the form of
        # {label: [random sequence]}
        # Hint: the keys of self.data can be used as labels

        # 주어진 n_tasks만큼 task를 생성한다.
        for task in range(n_tasks): 
            # 데이터의 label로 사용할 key를 n_way개 만큼 중복없이 샘플링한다.
            indices = random.sample(self.data.keys(), k=n_way)
            task_d = dict()

            # 선택된 n_way개의 key에 대해서, {label: [random sequence]} 형태의
            # task를 task_list에 추가한다.
            for indice in indices:
                data = random.sample(self.data[indice], k=n_query + n_support)
                task_d[indice] = data
            task_list.append(task_d)
            task_d = dict()
        ##################################################
        self.task_list = task_list

    def delete_task_list(self):
        self.task_list = None

    def visualize_random_task(self):
        s, _ = self.data_generator()

        for img in s:
            fig, axs = plt.subplots(
                1, self.n_support, figsize=(self.n_support, self.n_way)
            )
            for i in range(self.n_support):
                axs[i].imshow(img[i], cmap="gray")
                axs[i].axis("off")

        plt.show()

    def data_generator(self, task_idx=0):
        if self.task_list != None:
            # Deterministic task from predefined task space
            assert task_idx >= 0
            task = self.task_list[task_idx]

        else:
            self.generate_task_list(n_tasks=1)
            task = self.task_list[0]
            self.delete_task_list()

        support = np.zeros(
            [self.n_way, self.n_support, 28, 28, 1], dtype=np.float32
        )
        query = np.zeros(
            [self.n_way, self.n_query, 28, 28, 1], dtype=np.float32
        )

        ############### Your code here ###################
        # TODO: finish implementing this method.
        # Using a task generated by generate_task_list,
        # create a support and query dataset with shapes
        # (n_way, n_support/n_query, 28, 28, 1)

        # task = {label: item} 로 정의하였다.
        # task에는 n_way 개의 label이 있으므로
        # task의 모든 key를 traversal 하는 것은 n_way 번 반복하는 것과 같다.
        for i, (key, item) in enumerate(task.items()):
            # Assumption: len(item) >= n_support + n_query
            # 데이터가 ordering이 있는 sequence가 아니므로 slicing.
            s = np.asarray(item[: self.n_support])
            q = np.asarray(item[self.n_support : self.n_support + self.n_query])
            # (n_way, n_support/n_query, 28, 28, 1)
            support[i] = s
            query[i] = q
        ##################################################
        return support, query
    
    # random_way (=N) 라는 인자가 추가되었다.
    # 해당 인자가 0 이면, 주어진 n_way, n_shots에 대한 데이터를 생성하고
    # 해당 인자가 0 이 아닌 값이면, 해당 값으로 n_way를 설정하여 데이터를 생성한다.
    def random_data_generator(self, random_way=0):
        n_ways = [2, 3, 5, 6, 10, 15]
        n_shots = [15, 10, 6, 5, 3, 2]

        n_way = 0
        n_support = 0
        n_query = 0

        ############### Your code here ###################
        # TODO: Find numbers for n_way, n_support, n_query
        # where n_way * (n_support + n_query) == 30

        if random_way == 0: # Default setting, # of images = 30
            index = random.randrange(len(n_ways)-1)
            n_way = n_ways[index]
            n_shot = n_shots[index]
            n_support = random.randrange(1, n_shot)
            n_query = n_shot - n_support

            assert n_way * (n_support + n_query) == 30

        else:
            n_way = random_way

            # Assume that the number of images per class is exactly same.
            # Get the number of images per class.
            for key, item in self.data.items():
                images_per_class = len(item)
                break
            while True:
                n_shot = random.randrange(1, images_per_class)
                if n_shot > 1: break

            n_support = random.randrange(1, n_shot)
            n_query = n_shot - n_support

            assert n_way * (n_support + n_query) == n_way*n_shot
        ##################################################

        # Generate a random task
        self.generate_task_list(
            n_tasks=1, n_way=n_way, n_support=n_support, n_query=n_query
        )
        task = self.task_list[0]
        self.delete_task_list()

        support = np.zeros([n_way, n_support, 28, 28, 1], dtype=np.float32)
        query = np.zeros([n_way, n_query, 28, 28, 1], dtype=np.float32)

        ############### Your code here ###################
        # TODO: finish implementing this method.
        # create a support and query dataset with shapes
        # (n_way, n_support/n_query, 28, 28, 1)
        # (Same as in the data_generator method)
        for i, (key, item) in enumerate(task.items()):
            s = np.asarray(item[: n_support])
            q = np.asarray(
                item[n_support : n_support + n_query]
            )
            support[i] = s
            query[i] = q
        ##################################################
        # print(f'Support set: {n_way} ways - {n_support} shots')
        # print(f'Query set: {n_way} ways - {n_query} shots')
        return support, query